## ğŸš´â€â™‚ï¸ğŸ“ˆ Bike Rental Analysis with PySpark âš¡
Bienvenue dans ce projet Big Data oÃ¹ nous analysons les locations de vÃ©los en utilisant Apache Spark via PySpark dans un environnement DockerisÃ© ! ğŸ³âœ¨

## ğŸ“¦ Objectifs du Projet

ğŸ‘‰ Charger des donnÃ©es de location de vÃ©los depuis HDFS
ğŸ‘‰ RÃ©aliser un nettoyage et une exploration des donnÃ©es
ğŸ‘‰ Construire et entraÃ®ner un modÃ¨le de rÃ©gression par arbre de dÃ©cision ğŸŒ³
ğŸ‘‰ Ã‰valuer les performances du modÃ¨le ğŸ“Š
ğŸ‘‰ Comparer avec un modÃ¨le naÃ¯f (moyenne) pour Ã©valuer l'amÃ©lioration âœ…

## ğŸ—‚ï¸ Arborescence

projetbigdata/
â”œâ”€â”€ Bike.csv                    # ğŸ“„ Jeu de donnÃ©es
â”‚
â”œâ”€â”€ bike_rental_pyspark.py      #  Script PySpark
â”‚
â”œâ”€â”€ images/                     # ğŸ“¸ Dossier pour tes captures d'Ã©cran
â”‚   â”‚
â”‚   â”œâ”€â”€ pyspark_test1.png
â”‚   â”‚
â”‚   â”œâ”€â”€ pyspark_test2.png
â”‚   â”‚
â”‚   â”œâ”€â”€ img1.png
â”‚   â”‚
â”‚   â”œâ”€â”€ img2.png
â”‚   â”‚
â”‚   â”œâ”€â”€ img3.png
â”‚   â”‚
â”‚   â”œâ”€â”€ img4.png
â”‚   â”‚
â”‚   â””â”€â”€ img5.png
â”‚
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ Dockerfile.spark
â”‚
â””â”€â”€ README.md                   # ğŸ“– Documentation du projet

## ğŸ“Š DonnÃ©es utilisÃ©es

## ğŸ“‚ Bike.csv contenant :

datetime ğŸ•°ï¸

saison ğŸŒ¸ğŸŒğŸ‚â„ï¸

conditions mÃ©tÃ©o â˜ï¸ğŸŒ§ï¸ğŸŒ

tempÃ©rature ğŸŒ¡ï¸

humiditÃ© ğŸ’§

vitesse du vent ğŸŒ¬ï¸

nombre d'utilisateurs enregistrÃ©s et occasionnels ğŸ‘¥

total de locations ğŸ“ˆ

## ğŸš€ DÃ©ploiement & ExÃ©cution

### 1ï¸âƒ£ Configuration Initiale
#### Configuration du Cluster

### 2ï¸âƒ£ DÃ©marrage de l'Environnement
#### Lancement de l'Environnement

Lancer l'environnement distribuÃ©:
```bash
docker-compose up -d
```

![Lancement de l'Environnement](images/img3.png)

*DÃ©marrage des conteneurs Docker et initialisation des services*

### 3ï¸âƒ£ Tests PySpark
#### Test PySpark 1
![Test PySpark 1](images/pyspark_test1.jpg)

*Premier test de l'environnement PySpark*

#### Test PySpark 2
![Test PySpark 2](images/pyspark_test2.jpg)
*VÃ©rification de la configuration PySpark*

### 4ï¸âƒ£ Interface et Monitoring
#### Interface de l'Application
![Interface de l'Application](images/img1.png)
*Interface utilisateur pour le monitoring et la gestion*

### 5ï¸âƒ£ RÃ©sultats de l'Analyse
#### RÃ©sultats de l'Analyse
![RÃ©sultats de l'Analyse](images/img4.png)
*RÃ©sultats de l'analyse des donnÃ©es et des prÃ©dictions*

### 6ï¸âƒ£ Visualisations Finales
#### Visualisations Finales
![Visualisations Finales](images/img5.png)
*ReprÃ©sentations graphiques des rÃ©sultats finaux*

## ğŸ“¥ Transfert du dataset dans HDFS

```bash
docker cp Bike.csv namenode:/tmp/Bike.csv

docker exec -it namenode bash
hdfs dfs -mkdir -p /projetbigdata
hdfs dfs -put /tmp/Bike.csv /projetbigdata/

hdfs dfs -ls /projetbigdata
```

## ğŸ“¥ DÃ©ploiement et exÃ©cution du script PySpark

```bash
docker cp bike_rental_pyspark.py spark-master:/tmp/bike_rental_pyspark.py 
```

```bash
docker exec -it spark-master /opt/bitnami/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.executor.memory=2g \
    --conf spark.driver.memory=2g \
    /tmp/bike_rental_pyspark.py 
```

ğŸ“ Auteurs
ğŸ‘©â€ğŸ’» Samah Saidi